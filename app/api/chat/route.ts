import { NextRequest, NextResponse } from "next/server";
import OpenAI from "openai";
import { getVectorStore } from "@/lib/vectorStoreDB";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(request: NextRequest) {
  try {
    const { messages } = await request.json();

    if (!messages || !Array.isArray(messages)) {
      return NextResponse.json(
        { error: "Invalid messages format" },
        { status: 400 }
      );
    }

    // Get the last user message
    const lastMessage = messages[messages.length - 1];
    if (lastMessage.role !== "user") {
      return NextResponse.json(
        { error: "Last message must be from user" },
        { status: 400 }
      );
    }

    const userQuery = lastMessage.content;

    // Search vector store for relevant context
    const vectorStore = getVectorStore();
    const relevantDocs = await vectorStore.search(userQuery, 3);

    // Build context from relevant documents
    let context = "";
    if (relevantDocs.length > 0) {
      context = "Here is relevant information from the knowledge base:\n\n";
      relevantDocs.forEach((doc, i) => {
        context += `Document ${i + 1} (from ${doc.metadata.source}):\n${doc.content}\n\n`;
      });
      context += "---\n\n";
    } else {
      context =
        "Note: No relevant documents found in the knowledge base. Please answer based on general knowledge.\n\n";
    }

    // Create system message with context
    const systemMessage = {
      role: "system" as const,
      content: `You are a helpful AI assistant with access to a knowledge base. Use the provided context to answer questions accurately. If the context doesn't contain relevant information, say so and provide a general answer if appropriate.

${context}

Always cite which document you're using when answering from the knowledge base.`,
    };

    // Call OpenAI API
    const completion = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [systemMessage, ...messages],
      temperature: 0.7,
      max_tokens: 500,
    });

    const assistantMessage = completion.choices[0].message.content;

    // Add metadata about sources used
    const sources = relevantDocs.map((doc) => ({
      source: doc.metadata.source,
      page: doc.metadata.page,
    }));

    return NextResponse.json({
      message: assistantMessage,
      sources: sources.length > 0 ? sources : null,
      documentsSearched: vectorStore.getCount(),
    });
  } catch (error: any) {
    console.error("Chat error:", error);

    // Handle specific OpenAI errors
    if (error?.status === 401) {
      return NextResponse.json(
        { error: "Invalid OpenAI API key. Please check your .env file." },
        { status: 401 }
      );
    }

    return NextResponse.json(
      { error: "Failed to generate response" },
      { status: 500 }
    );
  }
}
